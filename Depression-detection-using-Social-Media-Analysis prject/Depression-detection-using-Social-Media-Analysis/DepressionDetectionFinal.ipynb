{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm used Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1  = pd.read_csv(r\"C:\\Users\\ASUS\\Desktop\\Depression-detection-using-Social-Media-Analysis\\datasetPart1.csv\")\n",
    "#data2  = pd.read_csv(r\"C:\\Users\\ASUS\\Desktop\\Depression-detection-using-Social-Media-Analysis\\datasetPart2.csv\")\n",
    "#values1=data1[['ItemID','Depressive','SentimentSource','SentimentText','Analytic','Clout','Authentic','Tone','pronoun','ppron','i','we','you','shehe','they','ipron','article','prep','auxverb','adverb','conj','negate','verb','adj','compare','interrog','posemo','negemo','anx','anger','sad','social','family','friend','focuspast','focuspresent','focusfuture']]\n",
    "#values2=data2[['ItemID','Depressive','SentimentSource','SentimentText','Analytic','Clout','Authentic','Tone','pronoun','ppron','i','we','you','shehe','they','ipron','article','prep','auxverb','adverb','conj','negate','verb','adj','compare','interrog','posemo','negemo','anx','anger','sad','social','family','friend','focuspast','focuspresent','focusfuture']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes=[values1,values2]\n",
    "#join=pd.concat(dataframes)\n",
    "#join.to_csv(r\"C:\\Users\\ASUS\\Desktop\\Depression-detection-using-Social-Media-Analysis\\output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\ASUS\\Desktop\\Depression-detection-using-Social-Media-Analysis\\output.csv\")\n",
    "data=data[['Id','ItemID','Depressive','SentimentSource','SentimentText','Analytic','Clout','Authentic','Tone','pronoun','ppron','i','we','you','shehe','they','ipron','article','prep','auxverb','adverb','conj','negate','verb','adj','compare','interrog','posemo','negemo','anx','anger','sad','social','family','friend','focuspast','focuspresent','focusfuture']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotional Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6835443037974683"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotional_process=data[['Depressive','posemo','negemo','anx','anger','sad']]\n",
    "X_emo=data_emotional_process.iloc[:,1:].values\n",
    "y_emo=data_emotional_process.iloc[:,0].values\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_emo,y_emo,test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=9,random_state=45,min_samples_split=5)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      1048\n",
      "           1       0.59      0.44      0.51       611\n",
      "\n",
      "    accuracy                           0.68      1659\n",
      "   macro avg       0.66      0.63      0.64      1659\n",
      "weighted avg       0.67      0.68      0.67      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic Style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6497890295358649"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_linguistic=data[['Depressive','pronoun','ppron','i','we','you','shehe','they','ipron','article','prep','auxverb','adverb','conj','negate','verb','adj','compare','interrog']]\n",
    "X_linguistic=data_linguistic.iloc[:,1:].values\n",
    "y_linguistic=data_linguistic.iloc[:,0].values\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_linguistic,y_linguistic,test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=9,random_state=45,min_samples_split=5)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      1048\n",
      "           1       0.53      0.46      0.49       611\n",
      "\n",
      "    accuracy                           0.65      1659\n",
      "   macro avg       0.62      0.61      0.61      1659\n",
      "weighted avg       0.64      0.65      0.64      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6081977094635322"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temporal_process=data[['Depressive','focuspast','focuspresent','focusfuture']]\n",
    "X_temporal=data_temporal_process.iloc[:,1:].values\n",
    "y_temporal=data_temporal_process.iloc[:,0].values\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_temporal,y_temporal,test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=9,random_state=45,min_samples_split=5)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69      1048\n",
      "           1       0.47      0.45      0.46       611\n",
      "\n",
      "    accuracy                           0.61      1659\n",
      "   macro avg       0.58      0.57      0.58      1659\n",
      "weighted avg       0.60      0.61      0.61      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depressive</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>...</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>25.89</td>\n",
       "      <td>50.00</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>93.26</td>\n",
       "      <td>13.32</td>\n",
       "      <td>58.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>...</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>46.37</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.97</td>\n",
       "      <td>25.77</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>18.82</td>\n",
       "      <td>6.93</td>\n",
       "      <td>92.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.52</td>\n",
       "      <td>14.81</td>\n",
       "      <td>14.81</td>\n",
       "      <td>...</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>14.81</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>65.46</td>\n",
       "      <td>22.08</td>\n",
       "      <td>94.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.38</td>\n",
       "      <td>...</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8288</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>&amp;quot;@tsmarsh it's tea with little squidgy ba...</td>\n",
       "      <td>87.27</td>\n",
       "      <td>30.86</td>\n",
       "      <td>43.37</td>\n",
       "      <td>96.76</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8289</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>&amp;quot;@wondertwin -  Well if you get one befor...</td>\n",
       "      <td>44.96</td>\n",
       "      <td>67.52</td>\n",
       "      <td>31.94</td>\n",
       "      <td>94.75</td>\n",
       "      <td>13.64</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8290</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>&amp;quot;6 students beaten last night in the dorm...</td>\n",
       "      <td>93.26</td>\n",
       "      <td>77.05</td>\n",
       "      <td>58.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.11</td>\n",
       "      <td>3.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.11</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8291</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>&amp;quot;7 days without prayer makes 1 weak&amp;quot;...</td>\n",
       "      <td>83.81</td>\n",
       "      <td>85.81</td>\n",
       "      <td>4.35</td>\n",
       "      <td>87.20</td>\n",
       "      <td>7.14</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8292</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>&amp;quot;9&amp;quot; trailer looks cool and steampunk...</td>\n",
       "      <td>85.92</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>98.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8293 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Depressive SentimentSource  \\\n",
       "0              0    Sentiment140   \n",
       "1              0    Sentiment140   \n",
       "2              1    Sentiment140   \n",
       "3              0    Sentiment140   \n",
       "4              0    Sentiment140   \n",
       "...          ...             ...   \n",
       "8288           1    Sentiment140   \n",
       "8289           0    Sentiment140   \n",
       "8290           0    Sentiment140   \n",
       "8291           1    Sentiment140   \n",
       "8292           1    Sentiment140   \n",
       "\n",
       "                                          SentimentText  Analytic  Clout  \\\n",
       "0                          is so sad for my APL frie...     25.89  50.00   \n",
       "1                        I missed the New Moon trail...     93.26  13.32   \n",
       "2                               omg its already 7:30 :O     46.37  50.00   \n",
       "3               .. Omgaga. Im sooo  im gunna CRy. I'...     18.82   6.93   \n",
       "4              i think mi bf is cheating on me!!!   ...     65.46  22.08   \n",
       "...                                                 ...       ...    ...   \n",
       "8288  &quot;@tsmarsh it's tea with little squidgy ba...     87.27  30.86   \n",
       "8289  &quot;@wondertwin -  Well if you get one befor...     44.96  67.52   \n",
       "8290  &quot;6 students beaten last night in the dorm...     93.26  77.05   \n",
       "8291  &quot;7 days without prayer makes 1 weak&quot;...     83.81  85.81   \n",
       "8292  &quot;9&quot; trailer looks cool and steampunk...     85.92  50.00   \n",
       "\n",
       "      Authentic   Tone  pronoun  ppron      i  ...  negemo  anx  anger    sad  \\\n",
       "0          3.37   1.00    10.00  10.00  10.00  ...   10.00  0.0   0.00  10.00   \n",
       "1         58.07   1.00    11.11  11.11  11.11  ...   11.11  0.0   0.00  11.11   \n",
       "2          4.97  25.77    11.11   0.00   0.00  ...    0.00  0.0   0.00   0.00   \n",
       "3         92.47   1.00    18.52  14.81  14.81  ...    3.70  0.0   0.00   3.70   \n",
       "4         94.81   1.00    15.38  15.38  15.38  ...    7.69  0.0   7.69   0.00   \n",
       "...         ...    ...      ...    ...    ...  ...     ...  ...    ...    ...   \n",
       "8288      43.37  96.76    15.00   0.00   0.00  ...    0.00  0.0   0.00   0.00   \n",
       "8289      31.94  94.75    13.64  13.64   4.55  ...    0.00  0.0   0.00   0.00   \n",
       "8290      58.07   1.00    11.11  11.11   3.70  ...    3.70  0.0   3.70   0.00   \n",
       "8291       4.35  87.20     7.14   3.57   0.00  ...    3.57  0.0   0.00   0.00   \n",
       "8292       1.00  98.87     0.00   0.00   0.00  ...    0.00  0.0   0.00   0.00   \n",
       "\n",
       "      social  family  friend  focuspast  focuspresent  focusfuture  \n",
       "0      10.00    0.00   10.00       0.00         10.00         0.00  \n",
       "1       0.00    0.00    0.00      11.11          0.00         0.00  \n",
       "2       0.00    0.00    0.00      11.11          0.00         0.00  \n",
       "3       0.00    0.00    0.00       7.41         14.81         3.70  \n",
       "4       7.69    0.00    7.69       0.00         15.38         0.00  \n",
       "...      ...     ...     ...        ...           ...          ...  \n",
       "8288    0.00    0.00    0.00       0.00         10.00         0.00  \n",
       "8289    9.09    0.00    0.00       4.55          9.09         0.00  \n",
       "8290    7.41    0.00    0.00      11.11          7.41         0.00  \n",
       "8291   14.29    3.57    3.57       0.00         14.29         3.57  \n",
       "8292    0.00    0.00    0.00       0.00          5.88         0.00  \n",
       "\n",
       "[8293 rows x 36 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(['ItemID'], axis = 1) \n",
    "data=data.drop(['Id'], axis = 1) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['SentimentSource'], axis = 1) \n",
    "data=data.drop(['SentimentText'], axis = 1) \n",
    "X=data.iloc[:,1:].values\n",
    "y=data.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.89, 50.  ,  3.37, ...,  0.  , 10.  ,  0.  ],\n",
       "       [93.26, 13.32, 58.07, ..., 11.11,  0.  ,  0.  ],\n",
       "       [46.37, 50.  ,  4.97, ..., 11.11,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [93.26, 77.05, 58.07, ..., 11.11,  7.41,  0.  ],\n",
       "       [83.81, 85.81,  4.35, ...,  0.  , 14.29,  3.57],\n",
       "       [85.92, 50.  ,  1.  , ...,  0.  ,  5.88,  0.  ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8293 entries, 0 to 8292\n",
      "Data columns (total 34 columns):\n",
      "Depressive      8293 non-null int64\n",
      "Analytic        8293 non-null float64\n",
      "Clout           8293 non-null float64\n",
      "Authentic       8293 non-null float64\n",
      "Tone            8293 non-null float64\n",
      "pronoun         8293 non-null float64\n",
      "ppron           8293 non-null float64\n",
      "i               8293 non-null float64\n",
      "we              8293 non-null float64\n",
      "you             8293 non-null float64\n",
      "shehe           8293 non-null float64\n",
      "they            8293 non-null float64\n",
      "ipron           8293 non-null float64\n",
      "article         8293 non-null float64\n",
      "prep            8293 non-null float64\n",
      "auxverb         8293 non-null float64\n",
      "adverb          8293 non-null float64\n",
      "conj            8293 non-null float64\n",
      "negate          8293 non-null float64\n",
      "verb            8293 non-null float64\n",
      "adj             8293 non-null float64\n",
      "compare         8293 non-null float64\n",
      "interrog        8293 non-null float64\n",
      "posemo          8293 non-null float64\n",
      "negemo          8293 non-null float64\n",
      "anx             8293 non-null float64\n",
      "anger           8293 non-null float64\n",
      "sad             8293 non-null float64\n",
      "social          8293 non-null float64\n",
      "family          8293 non-null float64\n",
      "friend          8293 non-null float64\n",
      "focuspast       8293 non-null float64\n",
      "focuspresent    8293 non-null float64\n",
      "focusfuture     8293 non-null float64\n",
      "dtypes: float64(33), int64(1)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=9,\n",
       "                       n_jobs=None, oob_score=False, random_state=45, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=9,random_state=45,min_samples_split=5)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7221217600964437"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      1048\n",
      "           1       0.64      0.57      0.60       611\n",
      "\n",
      "    accuracy                           0.72      1659\n",
      "   macro avg       0.70      0.69      0.69      1659\n",
      "weighted avg       0.72      0.72      0.72      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n"
     ]
    }
   ],
   "source": [
    "DepressiveTweets = np.count_nonzero(y_pred == 0)\n",
    "print(DepressiveTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n"
     ]
    }
   ],
   "source": [
    "NonDepressiveTweets = np.count_nonzero(y_pred == 1)\n",
    "print(NonDepressiveTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.209162145871\n"
     ]
    }
   ],
   "source": [
    "Total=DepressiveTweets+NonDepressiveTweets;\n",
    "IsDepressed=(DepressiveTweets/Total)*100;\n",
    "print(IsDepressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is depressed\n"
     ]
    }
   ],
   "source": [
    "if(IsDepressed>60):\n",
    "    print(\"The user is depressed\")\n",
    "else:\n",
    "    print(\"The user is not depressed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm-K-Nearest Neighbors(K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotional Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_emotional_process=data[['Depressive','posemo','negemo','anx','anger','sad']]\n",
    "X_emo=data_emotional_process.iloc[:,1:].values\n",
    "y_emo=data_emotional_process.iloc[:,0].values\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_emo,y_emo,test_size=0.2,random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.48      0.58      1048\n",
      "           1       0.45      0.73      0.56       611\n",
      "\n",
      "    accuracy                           0.57      1659\n",
      "   macro avg       0.60      0.60      0.57      1659\n",
      "weighted avg       0.64      0.57      0.57      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5877034358047016"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temporal_process=data[['Depressive','focuspast','focuspresent','focusfuture']]\n",
    "X_temporal=data_temporal_process.iloc[:,1:].values\n",
    "y_temporal=data_temporal_process.iloc[:,0].values\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_temporal,y_temporal,test_size=0.2,random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      1048\n",
      "           1       0.45      0.52      0.48       611\n",
      "\n",
      "    accuracy                           0.59      1659\n",
      "   macro avg       0.57      0.57      0.57      1659\n",
      "weighted avg       0.60      0.59      0.59      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic Style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6311030741410488"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_linguistic=data[['Depressive','pronoun','ppron','i','we','you','shehe','they','ipron','article','prep','auxverb','adverb','conj','negate','verb','adj','compare','interrog']]\n",
    "X_linguistic=data_linguistic.iloc[:,1:].values\n",
    "y_linguistic=data_linguistic.iloc[:,0].values\n",
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_linguistic,y_linguistic,test_size=0.2,random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.72      1048\n",
      "           1       0.50      0.40      0.44       611\n",
      "\n",
      "    accuracy                           0.63      1659\n",
      "   macro avg       0.59      0.58      0.58      1659\n",
      "weighted avg       0.62      0.63      0.62      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6817359855334539"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split;\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1048\n",
      "           1       0.57      0.56      0.57       611\n",
      "\n",
      "    accuracy                           0.68      1659\n",
      "   macro avg       0.66      0.66      0.66      1659\n",
      "weighted avg       0.68      0.68      0.68      1659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
